---
title: "Does OpenAI's loss on ChatGPT Pro mean they're doomed?"
date: 2025-01-06T12:00:00Z
slug: /01-06-does-openai-s-loss-on-chatgpt-pro-mean-they-re-doomed-/
description: "Before the jump comes here"
#image: images/2024/default-placeholder.png
#caption: Illustration...
categories:
  - blog
tags: # tags - one per line
  - AI    
# (uncomment to make hero post)  - feature
draft: false
---
A WhatsApp group that I'm part of has been discussing whether or not OpenAI is overvalued and in trouble as a result of this recent TechCrunch article.



The key point here is that they believe OpenAI is targeting a traditional mass market product with this £200-a-month offering. Several individuals in the group argue similarly, viewing this as a traditional tech start-up with a product that costs a significant amount to run, raising questions about scalability versus costs. Some members of the group discuss adverts as the natural evolution of any scaling tech platform. One person states, "Every platform, when it moves from being a tool to an infrastructure for discovery, ends up running ads."

I believe this is not the likely direction for OpenAI, nor do I think it is the basis for OpenAI's valuation. Ethan Mollick, who writes insightfully about AI, has a tweet that I find relevant. He discusses how confident the AI labs are in achieving something recognisable as artificial general intelligence (AGI). He mentions that while you don't have to believe them, he thinks they genuinely believe what they are saying, indicating that the labs are confident in their pursuit of superintelligence.

Putting aside the actual definition of superintelligence, I find it quite likely that incredibly useful and powerful AI, applicable to various problems, will emerge in the relatively near future. In his tweets on 6 January 2025, Ethan states, "I read a lot of social science papers on AI, and my conclusion is that there are far too few people rigorously studying the implications, good and bad, of LLMs. Computer science is producing a tide of good AI work. Economics, management, psychology, and psychosociology, etc., need to do the same."

In another tweet, he adds, "There's not a field that will be untouched by this technology, and everyone is desperate for any sort of research-backed advice on whether it is good to use AI, when it should be avoided, what it will do to our jobs, what it means for society, and how to avoid the harms and get the gains."

This is where I stand on this topic: it doesn't need to be AGI or superintelligence to impact every single field. It doesn't need to be AGI or superintelligence to affect many jobs across the developed services sector. This is where I believe the valuation of companies like OpenAI and Anthropic originates. I do not think that the most rewarding direction is simply selling £200-a-month personal ChatGPT subscriptions.

I believe the value and direction of travel, the reason for these astronomical valuations, is the significant possibility that these technologies could replace entire roles in organisations or at least entire units of work. If we can achieve significantly more with an AI that costs £2,000 a month, then that is a bargain. Once you start making a direct contribution to a company's bottom line, you can charge a substantial amount for that service.

After all, margin is what matters, not the total amount of transactions. If OpenAI can place a £2,000-a-month agent into a company, and that agent generates £2500 a month, that is an easy sell. It represents a great margin for most companies on such an investment, especially if it is scalable across several areas of the business. Therefore, I think those focusing on adverts and the potential losses associated with the (least efficient version of the) £200-a-month subscription may be missing the point.