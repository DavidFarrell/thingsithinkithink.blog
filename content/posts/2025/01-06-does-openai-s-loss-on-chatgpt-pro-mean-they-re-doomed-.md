---
title: "Does OpenAI's loss on ChatGPT Pro mean they're doomed?"
date: 2025-01-06T01:00:00Z
slug: /01-06-does-openai-s-loss-on-chatgpt-pro-mean-they-re-doomed-/
description: "I don't think so. ðŸ¤·"
image: images/2025/01-06-does-openai-s-loss-on-chatgpt-pro-mean-they-re-doomed.png
caption: Illustration...
categories:
  - blog
  - artificial-intelligence
tags: # tags - one per line
  - AI    
  - strategy
# (uncomment to make hero post)  - feature
draft: false
---
A WhatsApp group that I'm part of has been discussing whether or not OpenAI is overvalued and in trouble as a result of this recent [TechCrunch article](https://techcrunch.com/2025/01/05/openai-is-losing-money-on-its-pricey-chatgpt-pro-plan-ceo-sam-altman-says/).

The key point here is that they believe OpenAI is targeting a traditional mass market product with this Â£200-a-month offering. Several individuals in the group argue similarly, viewing this as a traditional tech start-up with a product that costs a significant amount to run, raising questions about scalability versus costs. Some members of the group discuss adverts as the natural evolution of any scaling tech platform. One person states, "Every platform, when it moves from being a tool to an infrastructure for discovery, ends up running ads."

I believe this is not the likely direction for OpenAI, nor do I think it is the basis for OpenAI's valuation. Ethan Mollick has a [tweet](https://x.com/emollick/status/1876119097660100636) that I find relevant. He discusses how confident the AI labs are in achieving something recognisable as artificial general intelligence (AGI). He mentions that while you don't have to believe them, he thinks *they* genuinely believe what they are saying, indicating that the labs are confident in their pursuit of superintelligence.


![Ethan Mollick tweets, summarising Sam Altman's recent statement, noting similarities to sentiments shared by the CEO of Anthropic and other AI researchers. The statement reflects confidence in achieving AGI, suggesting that by 2025, AI agents could enter the workforce and transform productivity. It also expresses ambition for developing superintelligent systems, aiming to accelerate innovation, increase prosperity, and enable advancements far beyond human capabilities. Mollick emphasizes that while belief in these claims isn't mandatory, those making them seem genuinely convinced.](/images/2025/01-06-ethan-mollick-other-tweet.png)

Putting aside the actual definition of superintelligence, I find it quite likely that incredibly useful and powerful AI, applicable to various problems, will emerge in the relatively near future. In these other tweets [Ethan points to the direction of travel](https://x.com/emollick/status/1876003591720251785).

![Ethan Mollick tweets saying `There's not a field that will be untouched by this technology, and everyone is desperate for any sort of research-backed advice on whether it is good to use AI, when it should be avoided, what it will do to our jobs, what it means for society, and how to avoid the harms and get the gains. I read a lot of social science papers on AI, and my conclusion is that there are far too few people rigorously studying the implications, good and bad, of LLMs. Computer science is producing a tide of good AI work. Economics, management, psychology, and psychosociology, etc., need to do the same.`](/images/2025/01-06-ethan-mollick-tweet.png)

This is where I stand on this topic: it doesn't need to be AGI or superintelligence to impact every single field. It doesn't need to be AGI or superintelligence to affect many jobs across the developed services sector. This is where I believe the valuation of companies like OpenAI and Anthropic originates. I do not think that the most rewarding direction is simply selling Â£200-a-month personal ChatGPT subscriptions.

I believe the value and direction of travel for these companies (and the core reason for their astronomical valuations) is the significant possibility that these technologies could replace entire roles in organisations or at least entire units of work. If we can achieve significantly more with an AI that costs Â£2,000 a month than we could without, then that is a bargain. Once you start making a direct contribution to a company's bottom line, you can charge a substantial amount for that service.

After all, margin is what matters, not the total amount of transactions. If OpenAI can place a Â£2,000-a-month "agent" ([whatever that means](https://lite.datasette.io/?json=https://gist.github.com/simonw/bdc7b894eedcfd54f0a2422ea8feaa80#/data/raw)) into a company, and that agent generates Â£2500 a month, that is an easy sell. It represents a great margin for most companies on such an investment, especially if it is scalable across several areas of the business. Therefore, I think those focusing on adverts and the potential losses associated with the (least efficient version of the) Â£200-a-month subscription may be missing the point.