---
title: "Podcast interview with Prof Alan Brown about uses of AI in Government"
date: 2024-12-05T12:00:00Z
slug: /12-05-podcast-interview-with-prof-alan-brown-about-uses-of-ai-in-government/
description: "descriptiongoeshere"
image: images/2024/1212_alan_brown.png
caption: Image of Prof. Brown being interviewed by Paul Zimmerman by Think Tank
categories:
  - uncategorized
tags:
  - ai
  - government
draft: true
---

I've been thinking recently about how to frame the ways that generative AI is going to make its way into enterprise and the public sector. A [recent podcast interview](https://www.youtube.com/watch?v=KOyovrkEhlk&list=PLWovoZxDVoYMQJzx9zpNjeJ3UNGuCwYLt&index=6) between [**Professor Alan Brown**](https://www.alanbrown.net/) and [**Think Tank**](https://thinktankproduction.co.uk/) touched upon this.

Alan spent nearly two decades in the USA driving large-scale software programmes and leading R&D teams. After roles at Carnegie Mellon University and as an IBM Distinguished Engineer, he's now focused on digital transformation. In addition to his research at [Exeter](https://experts.exeter.ac.uk/27811-alan-brown), he's recently published [_"Surviving and Thriving in the Age of AI"_](https://surviveaibook.com/) which aims to help digital leaders navigate the challenges and opportunities of AI.

I thought Alan's framing of the ways AI is being used in Government rang quite true to me.

---

## Large-Scale Formal Projects

The first involves large-scale projects requiring significant resourcesâ€”think facial recognition at borders or fraud detection across tax returns. These could be small 6 month projects or large investments, spanning three to four years, with formal requirements and extensive governance, rollout plans, change champions, etc. 

This is the 'devil we know' - yes, things are a wee bit different perhaps in the context of generative AI but we have a lot of knowledge about managing large-scale IT projects, much of which transfers to this new context. It's new, but it's not _new_ new.

So in some ways, "how will AI be used in government" can be answered along the lines of _the same way any other new technology is used_ - with a user centric, service design oriented methodology to provide high quality, citizen focused products and services. Duh.

---

## Informal Use and Shadow AI

The second way is through informal use, where staff might run queries through **ChatGPT** (of one of the myriad alternatives) to get outputs - for a whole variety of contexts and use cases and entirely 'off book'. This raises important questions, particularly around issues of data governance and accuracy. Hallucinations (where the system produces inaccurate information) might not happen _that_ often, but the consequences can be serious when they do. 

Government is by default risk averse (rightfully so) but this downside should be considered against what currently happens.

Are we confident that staff are always reading complex case notes in detail? What is worse, a person _not_ engaging with the material, or the material possibly containing a hallucination? I don't think the answers are easy here.

The default stance of risk averse organisations may be to discourage such use of AI. However, informal use happens regardless of oversight, bringing a pressure to focus on risk mitigation rather than outright prohibition. I'm reminded of [desire paths](https://en.wikipedia.org/wiki/Desire_path) where people ignore the designed paved route in favour of cutting across the grass.

---

## Embedded AI in Commercial Products

The third way is perhaps the most subtle: AI integration into commercial products. From email autocomplete to meeting summaries, to the "summarise this email" button that has appeared in my Gmail, AI is becoming embedded in our everyday tools (whether or not we asked for it). This integration makes it increasingly difficult to control or implement policies against AI use. 
