<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation | thingsithinkithink</title>

<meta name="description" content="Notes from lesson 4 of Hamel and Shreya&#39;s LLM evaluation course - handling multi-turn conversations and building evaluation criteria through collaboration.">
      <link rel="stylesheet" href="/css/main.min.80f29fb74d530136f20bd8f3c36d75c8a96e2026e849229670727aa4d68f7fbc.css" integrity="sha256-gPKft01TATbyC9jzw211yKluICboSSKWcHJ6pNaPf7w=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://thingsithinkithink.blog/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://thingsithinkithink.blog/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://thingsithinkithink.blog/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://thingsithinkithink.blog/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://thingsithinkithink.blog/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://thingsithinkithink.blog/">thingsithinkithink</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/about/">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/categories/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://thingsithinkithink.blog/">thingsithinkithink</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://thingsithinkithink.blog/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Notes from lesson 4 of Hamel and Shreya&#39;s LLM evaluation course - handling multi-turn conversations and building evaluation criteria through collaboration. </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4">

        <img class="w-12 h-12 bg-black rounded-full" src="https://thingsithinkithink.blog/images/goldfinch.jpg" alt="David Gérouville-Farrell avatar" width="1000" height="1000">

        <ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2">David Gérouville-Farrell</li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-08-21T12:00:00&#43;00:00">August 21, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            11 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">
            <img class="rounded-lg" src="https://thingsithinkithink.blog/images/2025/parlancecourse/08-21-nurtureboss-chatbot_hu_43a143f40f15510b.png" alt="" width="750" height="418">
        <figcaption class="text-center italic text-xs">NurtureBoss&#39;s leasing agent chatbot had to address the complexity of multi-turn evaluation</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <p>The fourth lesson of Hamel Husain and Shreya Shankar&rsquo;s <a href="https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/">LLM evaluation course</a> covered two distinct challenges: evaluating multi-turn conversations and building evaluation criteria through collaboration.</p>
<h2 id="part-one-multi-turn-evaluation-beyond-single-exchanges">Part One: Multi-turn Evaluation Beyond Single Exchanges</h2>
<p>Multi-turn evaluation presents unique challenges compared to single-turn interactions. The same analyse-measure-improve lifecycle applies, and binary criteria remain a good starting point. But conversations introduce new dimensions to consider.</p>
<h3 id="what-changes-with-multi-turn">What Changes with Multi-turn</h3>
<p>When evaluating multi-turn conversations, three aspects come into play that don&rsquo;t matter as much with individual turns:</p>
<ul>
<li>
<p><strong>Context and Memory</strong>: Does the AI remember earlier parts of the conversation? How does behaviour change as the conversation lengthens?</p>
</li>
<li>
<p><strong>Consistency</strong>: Do responses align across turns without contradictions?</p>
</li>
<li>
<p><strong>Overall Session Goals</strong>: Unlike single turn-response pairs, we care whether the entire session achieved the user&rsquo;s objective.</p>
</li>
</ul>
<p>The &ldquo;trace&rdquo; now encompasses the entire multi-turn conversation rather than a single exchange.</p>
<h3 id="two-levels-of-evaluation">Two Levels of Evaluation</h3>
<p>When evaluating conversations, you work at two levels of abstraction:</p>
<p><strong>Session Level</strong> (recommended starting point):</p>
<ul>
<li>Evaluates the entire conversation for goal achievement</li>
<li>Uses binary pass/fail initially</li>
<li>For NurtureBoss: A session fails if a prospect wanting a two-bedroom tour ends up with no clear tour options, even if individual responses were polite</li>
</ul>
<p><strong>Turn Level</strong> (for debugging):</p>
<ul>
<li>Assesses individual turn-by-turn responses</li>
<li>Measures quality, relevance, correctness, safety, tone</li>
<li>Challenging to scale across long conversations</li>
<li>Used specifically when you&rsquo;re debugging an overall problem identified at session level</li>
</ul>
<p>Start at session level and when you identify (through error analysis) a type of problem you need to solve, switch to turn level evaluation to debug specific it.</p>
<h3 id="practical-strategies-for-multi-turn-testing">Practical Strategies for Multi-turn Testing</h3>
<p><strong>Collecting Initial Traces</strong>: Don&rsquo;t overthink this. Aim for ~100 conversational traces using the dimensional approach from <a href="https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/">lesson 2</a>. Remember those three dimensions:</p>
<ul>
<li>Features/Intent (what users want to do)</li>
<li>Caller Status/Persona (who is asking)</li>
<li>Query Complexity/Scenario (how well-formed the request is)</li>
</ul>
<p>Have your team simulate different personas and create 10-15 conversations each, systematically covering these dimensions rather than creating random conversations. Just do anything you can to get an initial dataset.</p>
<p><strong>Finding and Fixing Failure Points</strong>: As you assess these multi-turn conversations, you&rsquo;ll discover errors that emerge at specific points in the trace. You need strategies that let you focus on these failure points and iterate on them specifically. There are two approaches depending on whether the issue is truly multi-turn or not.</p>
<p><strong>Isolating Failures</strong>: When errors appear partway through a conversation, try reproducing them as single-turn tests. If a shopping bot gives the wrong return policy on turn 4, test with a direct query: &ldquo;What&rsquo;s the return policy for product X?&rdquo; If it&rsquo;s still wrong, you&rsquo;ve identified a grounding or retrieval issue, not a multi-turn problem.</p>
<p><strong>Handling True Multi-turn Issues</strong>: For problems that genuinely stem from conversation context (forgetting earlier information, confusion between context elements), you basically freeze the conversation at the failure point. If an error only occurs on turn 4 and relates to context handling, snapshot those first four interactions - you&rsquo;re always kicking off from that fixed starting point for iteration and improvement.</p>
<p>This leverages how LLMs actually work - they don&rsquo;t innately remember conversations. Instead, a messages array gets sent back with every interaction, holding all previous back-and-forth exchanges. By freezing the messages array at the problem point, you create a consistent baseline for testing improvements. This makes perfect sense when you think about it.</p>
<p><strong>Testing Robustness Through Perturbation</strong>: Deliberately modify existing traces to test how your system handles mid-conversation changes. Test both completely <em>different intents</em> (user switches from booking a tour to asking about maintenance) and <em>additional constraints</em> to original intents (halfway through a restaurant recommendation, the user mentions their friend is vegetarian). You kind of just have to test this - there&rsquo;s no clever way to anticipate how the agent will react to these changes. This &ldquo;perturbation&rdquo; testing should be part of your standard approach for building robust multi-turn products.</p>
<p><strong>Performance Degradation</strong>: Ensure your test set includes conversations of varying lengths. Performance often drops in longer conversations - the system forgets context, contradicts earlier responses, or loses track of instructions. This degradation over length is something people frequently forget to test.</p>
<p><strong>Automation for Multi-turn</strong>: When creating an LLM-as-judge for multi-turn conversations, it evaluates binary criteria on the entire trace. The focus is on overall success/failure of the session rather than turn-by-turn assessment.</p>
<h3 id="five-key-takeaways-for-multi-turn-evaluation">Five Key Takeaways for Multi-turn Evaluation</h3>
<ol>
<li><strong>Start at session level, zoom to turn level only for debugging</strong></li>
<li><strong>Try to isolate multi-turn failures as single-turn tests</strong> to determine if they&rsquo;re truly multi-turn issues</li>
<li><strong>For true multi-turn issues, freeze the conversation at the failure point</strong> and use that as your iteration baseline</li>
<li><strong>Deliberately perturb your traces</strong> to test system robustness</li>
<li><strong>Vary conversation lengths in your test set</strong> to catch performance degradation</li>
</ol>
<h2 id="part-two-collaborative-evaluation-beyond-individual-judgment">Part Two: Collaborative Evaluation Beyond Individual Judgment</h2>
<p>The second half of the lesson addressed a common challenge: evaluation criteria are often subjective, and individual judgment has limitations.</p>
<h3 id="why-collaborate">Why Collaborate?</h3>
<p>Qualities like helpfulness, tone, creativity, or catchiness get interpreted differently by different people. Everyone has biases and blind spots, and no single expert covers all aspects relevant to understanding user needs.</p>
<p>This is also largely about taste. Whilst having great taste is useful - as it always has been in product - understanding that your taste is a starting point but not the endpoint is important. Collaborative evaluation is a technique to systematically bring in multiple human experts and stakeholders to define what good and bad mean. It&rsquo;s a technique to mitigate against bias, to broaden the technical expertise on evaluations, and to make sure that your individual taste is a starting point, not the endpoint.</p>
<p>The goal here is actually three things that are worth considering individually:</p>
<p><strong>Defining criteria</strong> - Getting clear on what you&rsquo;re even measuring in the first place</p>
<p><strong>Refining criteria</strong> - As you see more examples, your understanding evolves. When I was marking student papers, the way I marked the first paper wasn&rsquo;t the same as the last - examining dozens of approaches refines what you think good looks like. I&rsquo;d try to mitigate this by spending time working on a rubric and trying hard to stick to it, but also doing things like randomising - putting all the question ones in a pool and marking them in random order, then doing all the question twos in random order. That way no individual student is penalised or rewarded by being first or last in the cohort. But these techniques didn&rsquo;t solve the problem, they just mitigated some of the effects. Multiple perspectives help catch and account for this drift.</p>
<p><strong>Applying criteria reliably</strong> - Having a group gives you the option to detect differences and focus on them. This helps prevent momentary lapses and ensures consistency.</p>
<p>These three goals - define, refine, apply - are what collaborative evaluation is trying to achieve.</p>
<h3 id="the-friction-trade-off">The Friction Trade-off</h3>
<p><img src="/images/2025/parlancecourse/08-21-benevolent-dictators.png" alt="Benevolent Dictator vs Team models for evaluation"></p>
<p>Hamel introduces the concept of &ldquo;benevolent dictators&rdquo; - principal domain experts who make final calls on evaluation criteria. His point is around practicality primarily: complexity increases exponentially with every person added to the annotation process.</p>
<p>He estimates 75% of teams should probably use the benevolent dictator model, even in large companies, because they&rsquo;re likely working on product slices that aren&rsquo;t that complex.</p>
<p>My view is slightly different: I think it&rsquo;s basically a trade-off. Both things are true - if you have the benevolent dictator model, you&rsquo;re going to be more efficient and quicker, but you won&rsquo;t have all perspectives captured. More friction is worth it when diverse perspectives have high value (extremely diverse user base) or there&rsquo;s little margin for error. For most cases, having a single decision-maker is better than - and it&rsquo;s probably fine for most cases, just like Hamel says.</p>
<p>But this is really an issue of taste and a product decision about trade-offs rather than purely an evaluation methodology question.</p>
<p>The sweet spot is probably a principal domain expert who is empowered and influential, but maybe isn&rsquo;t the final word, with other perspectives balanced by the product lead. You basically need someone empowered to make decisions but not operating in a vacuum.</p>
<h3 id="the-collaborative-workflow">The Collaborative Workflow</h3>
<p>The workflow is very reminiscent of social sciences methods - grounded theory, having multiple coders. It&rsquo;s all very much like good practice from social sciences, just being applied to AI evaluation:</p>
<ol>
<li><strong>Assemble Team</strong>: 2+ annotators with relevant expertise/stakeholder views</li>
<li><strong>Draft Initial Rubric</strong>: Define criteria (e.g., &ldquo;Is email tone appropriate?&rdquo;) with initial pass/fail examples. You&rsquo;ll probably do multiple criteria at once.</li>
<li><strong>Select Shared Annotation Set</strong>: 20-50 diverse traces, including edge cases (though they sometimes say up to 100)</li>
<li><strong>Independent Annotation</strong>: Everyone labels traces without discussion - this is crucial because it surfaces rubric ambiguities</li>
<li><strong>Measure Inter-Annotator Agreement</strong>: Quantify consistency using Cohen&rsquo;s Kappa</li>
<li><strong>Alignment Sessions</strong>: Discuss disagreements to refine the rubric (not just to get the &ldquo;right&rdquo; label)</li>
<li><strong>Revise &amp; Iterate</strong>: Update rubric, relabel, remeasure until Kappa ≥ 0.6</li>
<li><strong>Finalise Rubric &amp; Gold Labels</strong>: Document the refined rubric and create consensus-labelled dataset</li>
</ol>
<p>Points 6 through 8 are the most important part, and these are the points I think most people are going to skip: disagreements aren&rsquo;t just opportunities to get the &ldquo;right&rdquo; label. They&rsquo;re opportunities to refine your rubric. If two annotators with the same rubric reach different conclusions, the rubric itself is probably ambiguous or subjective.</p>
<h3 id="understanding-cohens-kappa">Understanding Cohen&rsquo;s Kappa</h3>
<p>The workflow mentions using Kappa ≥ 0.6 as an indication of &ldquo;good enough&rdquo; agreement, but it might not be obvious to everyone what that actually means.</p>
<p>Raw agreement percentages can be misleading. If 90% of your traces are &ldquo;pass&rdquo; and only 10% are &ldquo;fail,&rdquo; random annotators would agree ~82% of the time just by chance. An 85% observed agreement might seem good, but the Kappa would only be ~0.17, revealing the agreement is mostly luck.</p>
<p>In contrast, with balanced 50/50 pass/fail classes, chance agreement would be 50%. That same 85% observed agreement would yield a Kappa of ~0.70, showing substantial real agreement beyond chance.</p>
<p>The interpretation scale (Landis &amp; Koch, 1977):</p>
<ul>
<li>&lt; 0: Poor</li>
<li>0.21-0.40: Fair</li>
<li>0.61-0.80: Substantial</li>
<li>0.81-1.00: Almost Perfect</li>
</ul>
<p>Aim for Kappa ≥ 0.6 for reliable labels.</p>
<h3 id="refining-the-rubric">Refining the Rubric</h3>
<p>When disagreements arise, the goal is to improve the rubric for future consistency. Strategies include:</p>
<p><strong>Clarifying Definitions</strong>: Turn vague criteria like &ldquo;handles ambiguity well&rdquo; into concrete requirements like &ldquo;asks at least one clarifying question.&rdquo;</p>
<p><strong>Adding Illustrative Examples</strong>: Include examples of good copy from your content team to guide evaluators who aren&rsquo;t content experts.</p>
<p><strong>Adding Decision Rules</strong>: Specify exactly how the system should handle tricky situations.</p>
<p><strong>Splitting Criteria</strong>: Sometimes disagreements reveal that people are focusing on different aspects of the same criterion. &ldquo;Helpfulness&rdquo; might need splitting into &ldquo;factual relevance&rdquo; and &ldquo;proactivity.&rdquo; This is why collaborative workflows are actually very useful - they reveal when a single criterion is trying to do two things at once.</p>
<p>This reminds me of Edward Tufte&rsquo;s principle from <a href="https://www.amazon.co.uk/Envisioning-Information-Edward-R-Tufte/dp/0961392118"><em>Envisioning Information</em></a> (which I used when teaching UX design):</p>
<blockquote>
<p>To clarify, add detail. Clutter and overload are not attributes of information, they are failures of design. If the information is in chaos, don&rsquo;t start throwing out information, instead fix the design.</p></blockquote>
<p>Apparent complexity often comes from vagueness. Adding the right specific details actually makes things simpler.</p>
<h3 id="the-value-of-the-process">The Value of the Process</h3>
<p>What you actually get from this collaborative process:</p>
<ol>
<li><strong>A refined rubric</strong> that&rsquo;s clear and unambiguous enough for anyone to apply consistently - this is often underemphasised but it&rsquo;s incredibly valuable</li>
<li><strong>Gold labels</strong> - high-confidence ground truth validated by multiple experts, which become your reference standards for training LLM judges and onboarding new team members</li>
</ol>
<p>Interestingly, LLMs can help refine rubrics. After you&rsquo;ve identified disagreements and made judgments about them, you can feed all this information to an LLM to propose rubric changes. But the human expertise and judgment must come first - the LLM is just a tool to help synthesise what you&rsquo;ve learned.</p>
<h2 id="why-product-perspective-matters-in-evaluation">Why Product Perspective Matters in Evaluation</h2>
<p><img src="/images/2025/parlancecourse/08-21-product-perspective-evaluation.png" alt="Generic vs specific property responses showing the difference between developer and product evaluation criteria"></p>
<p>A good example from the lesson demonstrated why domain expertise matters in evaluation. When asked about one-bedroom apartments, the NurtureBoss bot provided a generic response mentioning &ldquo;peaceful atmosphere&rdquo; and &ldquo;prime location.&rdquo;</p>
<p>The scenario here would be two separate evaluators annotating the same LLM output. A developer might annotate this as a pass - it&rsquo;s technically correct, mentions one-bedrooms, and asks about move-in dates. But a product manager would fail it immediately.</p>
<p>The distinction is where product taste comes in: this system is meant to drive sales. Generic copy that could describe any property doesn&rsquo;t convert prospects. Effective responses need specific property information, compelling details, and concrete value propositions. A response about &ldquo;peaceful atmosphere&rdquo; tells prospects nothing they couldn&rsquo;t assume about dozens of other properties.</p>
<p>This illustrates why you shouldn&rsquo;t outsource annotation to people without domain expertise. An LLM judge trained without this product perspective would miss what makes a response actually useful for the business. The technical accuracy that satisfies a developer&rsquo;s criteria can be entirely inadequate for achieving business objectives.</p>
<h2 id="thingsithinkithink">thingsithinkithink</h2>
<ul>
<li>
<p>Perturbation testing is nice - I have struggled to frame the problem of detecting a directional shift in user intent - and I haven&rsquo;t really wrangled with it enough to feel comfortable - I think this will help.</p>
</li>
<li>
<p>Criteria drift is real and consistently underacknowledged in my experience. Every complex evaluation task I&rsquo;ve done has involved my standards evolving as I see more examples. .</p>
</li>
</ul>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/llm/">Llm</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/evaluation/">Evaluation</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/machine-learning/">Machine-Learning</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/multi-turn/">Multi-Turn</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/collaboration/">Collaboration</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/course-notes/">Course-Notes</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      
      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/07-06-llm-evals-course-lesson-3-automated-evaluators/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl"><img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/07_06_llm_as_a_judge_lifecycle_hu_c9378dbf5f2352bd.png" alt="LLM Evals Course Lesson 3: Building Automated Evaluators" width="750" height="515">

	  </figure>

	<div class="p-6">

		<time datetime="2025-07-06T08:00:00&#43;00:00">Jul 06, 2025</time>

		<h3 class="my-4 text-2xl font-bold">LLM Evals Course Lesson 3: Building Automated Evaluators</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Notes from lesson 3 of Hamel and Shreya&#39;s LLM evaluation course - implementing automated evaluators, building reliable LLM-as-judge systems, and avoiding common pitfalls.</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/06-22-llm-evals-course-lesson-2b-office-hrs/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl"><img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/06-22-llm-evals-course-lesson-2b-office-hrs_hu_4dc522b49194fd95.png" alt="LLM Evals Course: Lesson 2b (office hrs)" width="750" height="1125">

	  </figure>

	<div class="p-6">

		<time datetime="2025-06-22T09:00:00&#43;00:00">Jun 22, 2025</time>

		<h3 class="my-4 text-2xl font-bold">LLM Evals Course: Lesson 2b (office hrs)</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">A few things from Evals Course office hrs following lesson 2 of Hamel and Shreya&#39;s LLM evaluation course.</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/2024/infinite_archive.png" alt="things i think i think abstract image of waves and a stick figure">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">things i think i think</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/08-21-llm-evals-course-lesson-4-multiturn-collaborative-evaluation/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/08-21-nurtureboss-chatbot_hu_6fba18b2e44fe413.png" alt="LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation" width="250" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/08-16-isaac-flath-fasthtml-annotation-tools/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/08-16-isaac-fasthtml-hero_hu_3a855661f34ddb2d.png" alt="Building Domain-Specific Annotation Tools with FastHTML: Lessons from Isaac Flath" width="250" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Building Domain-Specific Annotation Tools with FastHTML: Lessons from Isaac Flath</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/08-16-where-to-host-fasthtml-apps/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/08_16_fasthtml_hu_d8ed29943a89e291.png" alt="Where to Host Your FastHTML Apps" width="250" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Where to Host Your FastHTML Apps</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/07-18-chrome-devtools-fasthtml-development/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/07-18-devtools-hero_hu_5c00c41a946b70ea.png" alt="Connecting Chrome DevTools to FastHTML Apps for Rapid Style Iteration" width="250" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Connecting Chrome DevTools to FastHTML Apps for Rapid Style Iteration</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/07-06-llm-evals-course-lesson-3-automated-evaluators/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/07_06_llm_as_a_judge_lifecycle_hu_867bfebf996587c9.png" alt="LLM Evals Course Lesson 3: Building Automated Evaluators" width="250" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">LLM Evals Course Lesson 3: Building Automated Evaluators</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://thingsithinkithink.blog/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">thingsithinkithink</span>
      </a>

      <p class="font-semibold">
        
      </p>

      

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	
	
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://linkedin.com/in/davidfarrell81" target="_blank" rel="noopener noreferrer">
			<img src="/images/linkedin-color-svgrepo-com.svg" alt="LinkedIn Logo" class="w-8 h-8">
		</a>
	</li>
	
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://github.com/DavidFarrell/" target="_blank" rel="noopener noreferrer">
			<img src="/images/github-mark.svg" alt="GitHub Logo" class="w-8 h-8">
		</a>
	</li>
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://bsky.app/profile/dgerouvillefarrell.bsky.social" target="_blank" rel="noopener noreferrer">
			<img src="/images/Bluesky_Logo.svg" alt="Bluesky Logo" class="w-8 h-8">
		</a>
	</li>
	
	
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/about/">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/categories/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">
      Powered by 
      <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>, 
      <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> 
      and based on the 
      <a href="https://pehtheme-hugo.netlify.app/" target="_blank" rel="noopener">pehtheme</a> theme.
    </p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>