<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>LLM Evals Lesson 8: Improving LLM Products | thingsithinkithink</title>

<meta name="description" content="Notes from the final lesson of Hamel and Shreya&#39;s LLM evaluation course - practical strategies for improving accuracy and reducing costs through prompt refinement, architecture changes, fine-tuning, and model cascades.">
      <link rel="stylesheet" href="/css/main.min.80f29fb74d530136f20bd8f3c36d75c8a96e2026e849229670727aa4d68f7fbc.css" integrity="sha256-gPKft01TATbyC9jzw211yKluICboSSKWcHJ6pNaPf7w=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://thingsithinkithink.blog/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://thingsithinkithink.blog/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://thingsithinkithink.blog/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://thingsithinkithink.blog/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://thingsithinkithink.blog/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://thingsithinkithink.blog/">thingsithinkithink</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/about/">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/categories/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://thingsithinkithink.blog/">thingsithinkithink</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://thingsithinkithink.blog/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">LLM Evals Lesson 8: Improving LLM Products</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Notes from the final lesson of Hamel and Shreya&#39;s LLM evaluation course - practical strategies for improving accuracy and reducing costs through prompt refinement, architecture changes, fine-tuning, and model cascades. </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4">

        <img class="w-12 h-12 bg-black rounded-full" src="https://thingsithinkithink.blog/images/goldfinch.jpg" alt="David Gérouville-Farrell avatar" width="1000" height="1000">

        <ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2">David Gérouville-Farrell</li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-12-21T09:00:00&#43;00:00">December 21, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            10 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">
            <img class="rounded-lg" src="https://thingsithinkithink.blog/images/2025/parlancecourse/12-21-improve-phase-intro_hu_7e3853880223e050.png" alt="" width="750" height="422">
        <figcaption class="text-center italic text-xs">The Analyse-Measure-Improve cycle that forms the backbone of systematic LLM evaluation</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <p>The final lesson of Hamel Husain and Shreya Shankar&rsquo;s <a href="https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/">LLM evaluation course</a> covered practical strategies for the &ldquo;Improve&rdquo; phase of the evaluation lifecycle. This post focuses on that lesson content in detail.</p>
<hr>
<h2 id="improving-llm-based-systems">Improving LLM-Based Systems</h2>
<p>With analysis and measurement complete, we can finally focus on improving our system. The lesson covered two areas: accuracy optimisation and cost reduction.</p>
<h3 id="improving-accuracy-quick-wins">Improving Accuracy: Quick Wins</h3>
<p>Quick wins close the Gulf of Specification. If you&rsquo;ve done error analysis properly, you&rsquo;ll probably find a bunch of quick wins. You thought the system worked a certain way, you discovered it doesn&rsquo;t, and often the fix is straightforward.</p>
<p><img src="/images/2025/parlancecourse/12-21-quick-wins-prompt-refinement.png" alt="Quick wins for accuracy improvement"></p>
<p><strong>Prompt refinement</strong>: Clarify ambiguous wording. Add targeted few-shot examples for specific failures. Use role-based guidance.</p>
<p>On role-based guidance: there&rsquo;s been commentary recently following <a href="https://arxiv.org/abs/2512.05858">research from Ethan Mollick&rsquo;s team</a> showing that expert persona prompts don&rsquo;t improve factual accuracy. If you say &ldquo;you are a genius math wizard&rdquo; versus &ldquo;you barely passed maths&rdquo;, there&rsquo;s no measurable difference in performance.</p>
<p><img src="/images/2025/parlancecourse/12-21-persona-prompting-research.png" alt="Simon Willison commenting on the persona prompting research"></p>
<p>But that doesn&rsquo;t make role-based guidance useless (so I disagree slightly with the great <a href="https://simonwillison.net/">Simon Willison</a> here). The benefit isn&rsquo;t about inducing accuracy. It&rsquo;s about inducing perspective. A tax adviser has a certain <a href="https://mixmusiceducationplatform.eu/en/episthemic-frames-in-theory/">epistemic frame</a> (a concept from <a href="https://en.wikipedia.org/wiki/David_Williamson_Shaffer">David Williamson Shaffer</a>): they&rsquo;re concerned about certain things, looking for certain patterns, communicating in certain ways. Telling an LLM it&rsquo;s a school teacher versus a tax adviser changes how it responds in ways that matter for your use case. Different, not more accurate.</p>
<p><strong>Step-by-step reasoning</strong>: Adding examples of how to think through problems can improve performance on tasks requiring logic or planning. Though with reasoning models now available, this has become less critical. There&rsquo;s even <a href="https://arxiv.org/abs/2410.21333">evidence</a> that chain-of-thought prompting can harm reasoning models, and <a href="https://platform.openai.com/docs/guides/reasoning-best-practices">OpenAI&rsquo;s own guidance</a> notes that instructing the model to &ldquo;think step by step&rdquo; may not enhance performance and can sometimes hinder it. If you&rsquo;re not using a reasoning model, it&rsquo;s probably still valuable. If you are, there&rsquo;s more nuance than the slide suggests.</p>
<h3 id="improving-accuracy-medium-effort-changes">Improving Accuracy: Medium-Effort Changes</h3>
<p>Medium-effort changes impact architecture more significantly.</p>
<p><img src="/images/2025/parlancecourse/12-21-medium-effort-structural-changes.png" alt="Medium effort changes for accuracy improvement"></p>
<p><strong>Task decomposition</strong>: Breaking a complex LLM call into a chain of smaller, focused calls. I had to do this on a recent Foreign Office project. People don&rsquo;t really ask direct questions. They describe their situation in a paragraph, and often there are two or three separate questions buried inside. We built a stage of our pipeline that decomposes the original paragraph into up to three separate intentions, rewrites each as a focused query, then answers them separately rather than all at once.</p>
<p>Start simple though. See if your system can handle things in one go. If it can&rsquo;t, then decompose.</p>
<p><strong>Tuning RAG components</strong>: Often the problem is retrieval, not generation. The slide mentions chunking strategies and number of documents retrieved. In my experience, a common issue is assumptions baked into RAG implementations. People use vector similarity search and don&rsquo;t leave space for keyword search or BM25. Revisiting those assumptions, trying hybrid retrieval mixing old-school keyword search with semantic search, can help considerably.</p>
<p><strong>Fixing tool misuse</strong>: Tool descriptions, parameters, and expected formats matter. One thing I really like about MCP is that it advertises tool descriptions. I was recently working on a system connecting an MCP server to a Microsoft Copilot agent. I realised I could shift complexity into the tool descriptions and patch the live system without redeploying code, because the agent reads tool descriptions when they change. I can add parameters, tweak function names, give more context on choosing between tools. It&rsquo;s a low-friction way to iterate. The Gulf of Specification applies to tools as well as prompts.</p>
<h3 id="improving-accuracy-advanced-strategies">Improving Accuracy: Advanced Strategies</h3>
<p><img src="/images/2025/parlancecourse/12-21-advanced-strategies.png" alt="Advanced strategies for accuracy improvement"></p>
<p><strong>Fine-tuning</strong>: Use when you have hundreds of high-quality labelled examples for a recurring failure that prompting can&rsquo;t fix. It&rsquo;s more expensive and you need to continually fine-tune as base models improve. Shreya made the point that you fine-tune 3.5 to match 4, then 4 comes out and beats your fine-tune anyway.</p>
<p>I expected when I started working with LLMs that I&rsquo;d be doing lots of fine-tuning. I spent time last year fine-tuning a Llama model on government content guidance. I got close to parity with OpenAI endpoints, but it was so much work (not the training itself, but organising the data, curating it properly, ensuring the right diversity, etc.), and if anything changed we&rsquo;d have to redo everything. In practice, I&rsquo;ve never actually needed fine-tuning in the wild. Architecture, tool descriptions, and prompting have always been enough. Fine-tuning makes sense for high-volume narrow tasks where you want performance and deployment cost benefits from a small model. But you also need institutional MLOps maturity to host, deploy, maintain, and keep it updated. Unless you&rsquo;re fundamentally an AI company, you probably shouldn&rsquo;t build those capabilities.</p>
<p><strong>Systematic prompt optimisation</strong>: Tools like DSPy treat the prompt as a tunable artefact. I keep expecting this to be really valuable, and so far I haven&rsquo;t been convinced. I think you need to be very mature in your understanding of your system to benefit. Things move so fast. I&rsquo;ve only dabbled, so I can&rsquo;t say definitively, but it feels like a dead end for now (to me, although I expect to be wrong at some point here).</p>
<p><strong>Human review loops</strong>: For high-stakes tasks, build interfaces for regular human review to constantly feed new examples into your datasets. This is the one advanced strategy I&rsquo;ve actually used. On the Foreign Office project, we built an interface so staff could maintain the dataset and tweak rules that end up in the prompts. They don&rsquo;t know they&rsquo;re prompt engineering, but they are.</p>
<hr>
<h3 id="cost-reduction-simple-strategies">Cost Reduction: Simple Strategies</h3>
<p>The simplest approach: use the cheapest model that can get the task done.</p>
<p><img src="/images/2025/parlancecourse/12-21-cost-reduction-simple-strategies.png" alt="Simple cost reduction strategies"></p>
<p>The way I work: get the system running with whatever model I can, then swap out AI components for cheaper alternatives. Classification tasks don&rsquo;t need GPT-5 or Claude Opus. On the Foreign Office project, we used GPT-3.5 for task decomposition and headline selection, but GPT-4 for the actual question-answer matching because 3.5 couldn&rsquo;t handle it.</p>
<p>In my current gig, I&rsquo;m happily using GPT-5 with thinking during prototyping, but I&rsquo;ll swap to non-reasoning or smaller models for production.</p>
<p><strong>Reduce token count</strong>: Consider how you want the LLM to respond. One or two word answers where appropriate. Use compact formats like YAML or XML instead of JSON if you&rsquo;re not doing tool calling.</p>
<p><strong>Leverage caching</strong>: Structure prompts with static content first, dynamic content last. This maximises cache hits.</p>
<h3 id="how-kv-caching-works">How KV Caching Works</h3>
<p>The slide on KV caching assumes you know what Key and Value vectors are.</p>
<p><img src="/images/2025/parlancecourse/12-21-kv-caching-deep-dive.png" alt="KV Caching explanation"></p>
<p>In Transformer models, the model calculates Key (K) and Value (V) vectors for every token to understand context. This is computationally expensive. KV Caching stores these intermediate calculations so they don&rsquo;t need to be recomputed.</p>
<p>A provider&rsquo;s KV cache only helps if the prefix of your prompt is identical. If you put the user&rsquo;s question at the top and context below, the user question won&rsquo;t be cached and you branch into a different pathway immediately. Put context first, user question last, and you get all those cached tokens before branching on the new content.</p>
<h3 id="what-caching-actually-saves">What Caching Actually Saves</h3>
<p>The discounts are substantial. Here&rsquo;s what the major providers currently offer (as of 21st December 2025):</p>
<p><strong>OpenAI</strong>: Up to 90% off input tokens on cache hits, model-dependent. GPT-5-mini cached input is $0.025/MTok versus $0.25/MTok standard (90% reduction).</p>
<p><strong>Anthropic (Claude)</strong>: Cache reads are 0.1× base input price (90% off). Cache writes cost more: 1.25× base for 5-minute caches, 2× base for 1-hour caches. Claude Sonnet 4.5 base input is $3/MTok, cache hits $0.30/MTok.</p>
<p><strong>Google Gemini</strong>: 90% discount on Gemini 2.5 models, 75% on Gemini 2.0. Gemini 2.5 Flash-Lite input is $0.10/MTok, context caching $0.01/MTok.</p>
<p><strong>Batching</strong> adds another 50% discount across all three providers. Combined with caching, the reused portion can land around 5% of normal cost.</p>
<p>For example: 100 requests with a 10k-token repeated prefix, 1k new input, 1k output using Claude Sonnet 4.5. Without caching, input costs $3.30. With caching (paying for one cache write, then 99 cache hits), input costs roughly $0.63. About 81% input savings.</p>
<p>Hamel noted that you used to have to explicitly enable caching. Now it&rsquo;s generally automatic. Here&rsquo;s a minimal OpenAI example showing how to check cache hits:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> openai <span style="color:#f92672">import</span> OpenAI
</span></span><span style="display:flex;"><span>client <span style="color:#f92672">=</span> OpenAI()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Needs to be long (&gt;= 1024 tokens) for caching to kick in</span>
</span></span><span style="display:flex;"><span>STATIC_PREFIX <span style="color:#f92672">=</span> (<span style="color:#e6db74">&#34;You are a concise assistant.</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">+</span> (<span style="color:#e6db74">&#34;background &#34;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">2000</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">call</span>(question: str):
</span></span><span style="display:flex;"><span>    r <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>responses<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-4.1-mini&#34;</span>,
</span></span><span style="display:flex;"><span>        input<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>            {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: STATIC_PREFIX},
</span></span><span style="display:flex;"><span>            {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: question},
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> r
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>r1 <span style="color:#f92672">=</span> call(<span style="color:#e6db74">&#34;Reply with exactly one word: hello&#34;</span>)
</span></span><span style="display:flex;"><span>r2 <span style="color:#f92672">=</span> call(<span style="color:#e6db74">&#34;Reply with exactly one word: goodbye&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;cached_tokens call 1:&#34;</span>, r1<span style="color:#f92672">.</span>usage[<span style="color:#e6db74">&#34;prompt_tokens_details&#34;</span>][<span style="color:#e6db74">&#34;cached_tokens&#34;</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;cached_tokens call 2:&#34;</span>, r2<span style="color:#f92672">.</span>usage[<span style="color:#e6db74">&#34;prompt_tokens_details&#34;</span>][<span style="color:#e6db74">&#34;cached_tokens&#34;</span>])
</span></span></code></pre></div><p>See also <a href="https://ai.intellectronica.net/cost-control-guide">Eleanor&rsquo;s blog post on cost control</a>.</p>
<hr>
<h3 id="advanced-cost-reduction-model-cascades">Advanced Cost Reduction: Model Cascades</h3>
<p>Model cascades route queries between cheap and expensive models based on confidence. The idea is basically to start with a cheap &ldquo;proxy&rdquo; model, and if it&rsquo;s unsure, escalate to an expensive &ldquo;oracle&rdquo; model. Answer easy questions cheaply, save the expensive model for hard problems.</p>
<p><img src="/images/2025/parlancecourse/12-21-model-cascade-flowchart.png" alt="Model cascade dataflow"></p>
<p>The goal is to find a confidence threshold T such that the cascade&rsquo;s accuracy meets your target (say 90%) when compared to always using the oracle.</p>
<h3 id="log-probabilities-and-confidence">Log Probabilities and Confidence</h3>
<p><img src="/images/2025/parlancecourse/12-21-logprobs-explained.png" alt="What are log probabilities?"></p>
<p>Most LLM APIs can return the log probability for each token generated. A logprob is the logarithm of the probability the model assigned to its chosen token. Values closer to 0 mean higher probability (higher confidence).</p>
<p>For classification tasks where the model outputs one of a few possible tokens (Pass/Fail, True/False, A/B/C), you can use logprobs to calculate a confidence score:</p>
<ol>
<li>Run the proxy model and get logprobs for each possible output</li>
<li>Convert back to probabilities (prob = e^logprob)</li>
<li>Normalise them to sum to 1</li>
<li>The normalised probability for the chosen token is your confidence score</li>
</ol>
<p><img src="/images/2025/parlancecourse/12-21-logprobs-classification-example.png" alt="Using logprobs for classification"></p>
<p>If confidence exceeds threshold T, return the proxy&rsquo;s answer. Otherwise, escalate to the oracle.</p>
<h3 id="tuning-the-threshold">Tuning the Threshold</h3>
<p><img src="/images/2025/parlancecourse/12-21-cascade-threshold-tuning.png" alt="Building the cascade: tuning the threshold"></p>
<p>The process:</p>
<ol>
<li>Take a labelled development dataset</li>
<li>Run the proxy on all examples to get predictions and confidence scores</li>
<li>Iterate through possible thresholds</li>
<li>For each threshold, simulate the cascade&rsquo;s accuracy and cost</li>
<li>Pick the threshold that meets your accuracy target at the cheapest cost</li>
</ol>
<p><img src="/images/2025/parlancecourse/12-21-cascade-algorithm-sketch.png" alt="Model cascade algorithm"></p>
<p>For generative tasks without discrete class labels, you treat all examples as a single group and evaluate the proxy&rsquo;s output against a gold answer using a binary pass/fail judgement, often performed by an LLM-as-judge.</p>
<h3 id="a-few-reservations-about-this-approach">A Few Reservations About This Approach</h3>
<p>I have fundamental issues with model cascades built on log probabilities.</p>
<p>The entire approach hinges on a strong relationship between model confidence and model correctness. I don&rsquo;t believe that relationship is reliable. LLMs will confidently give you wrong answers. They do it all the time. Log probability measures something about the model&rsquo;s internal state, but that <em><strong>something</strong></em> isn&rsquo;t specifically <em><strong>truth</strong></em>.</p>
<p>Shreya acknowledges this is more reliable for classification tasks than generative ones. She finds value in binary true/false tasks. I understand why it works there, but I think it&rsquo;s somewhat accidental. These are language models, not classification models. The logprob happens to correlate with correctness in narrow constrained cases, but it&rsquo;s not <em><strong>exactly</strong></em> measuring what we want it to measure.</p>
<p>For open-ended generation, defining a confidence score is much harder. Heuristics like &ldquo;average logprob per token&rdquo; exist but are less reliable. And the majority of what people use LLMs for these days are generative tasks: conversations, unstructured data processing, content creation. Not simple classifications.</p>
<p>A good example of the limitations of this approach can be seen in the recent GPT-5 router debacle. One would assume it&rsquo;s doing something like this under the hood, routing queries based on complexity. It didn&rsquo;t really work well for them. If OpenAI can&rsquo;t make it work reliably, I&rsquo;m sceptical anyone can.</p>
<p>This doesn&rsquo;t mean it will never be viable. But at this time, I&rsquo;m not convinced. The recent <a href="https://openai.com/index/why-language-models-hallucinate/">OpenAI work on hallucination</a> has similar ideas about training models to attend to their own confidence. I have similar reservations. These systems have a statistical probability-based architecture, not a logic-based one. We&rsquo;re trying to force them to be something they&rsquo;re not.</p>
<hr>
<h2 id="thingsithinkithink">thingsithinkithink</h2>
<ul>
<li>
<p>Fine-tuning continues to be something I expect to need and never actually use. The institutional capability required to maintain fine-tuned models is substantial, and foundation models keep improving faster than you can fine-tune.</p>
</li>
<li>
<p>My scepticism about log probabilities as confidence measures extends to related ideas like training models to know when they&rsquo;re uncertain. The architecture doesn&rsquo;t support it. Statistical confidence isn&rsquo;t epistemic confidence. I look forward to being wrong about this.</p>
</li>
<li>
<p>Role-based guidance remains useful despite the Mollick paper. Different versus more accurate. The epistemic frame of a persona shapes responses in ways that matter even if raw accuracy doesn&rsquo;t change.</p>
</li>
</ul>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/llm/">Llm</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/evaluation/">Evaluation</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/machine-learning/">Machine-Learning</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/cost-optimisation/">Cost-Optimisation</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/course-notes/">Course-Notes</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/feature/">Feature</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      
      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/10-12-llm-evals-course-lesson-6-complex-pipelines-cicd/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl"><img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/10_12_lesson6_transition_failure_matrix_hu_a92d5ddba1ed610c.png" alt="LLM Evals Course Lesson 6: Complex Pipelines and CI/CD" width="750" height="422">

	  </figure>

	<div class="p-6">

		<time datetime="2025-10-12T09:00:00&#43;00:00">Oct 12, 2025</time>

		<h3 class="my-4 text-2xl font-bold">LLM Evals Course Lesson 6: Complex Pipelines and CI/CD</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Notes from lesson 6 of Hamel and Shreya&#39;s LLM evaluation course - debugging agentic systems, handling complex data modalities, and implementing CI/CD for production LLM applications.</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2025/08-21-llm-evals-course-lesson-4-multiturn-collaborative-evaluation/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl"><img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2025/parlancecourse/08-21-nurtureboss-chatbot_hu_43a143f40f15510b.png" alt="LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation" width="750" height="418">

	  </figure>

	<div class="p-6">

		<time datetime="2025-08-21T12:00:00&#43;00:00">Aug 21, 2025</time>

		<h3 class="my-4 text-2xl font-bold">LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Notes from lesson 4 of Hamel and Shreya&#39;s LLM evaluation course - handling multi-turn conversations and building evaluation criteria through collaboration.</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/2024/infinite_archive.png" alt="things i think i think abstract image of waves and a stick figure">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">things i think i think</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2026/01-26-claude-agent-sdk-part-3/"></a>
	<figure class="basis-1/3 aspect-video overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2026/01-26-claude-agent-sdk-part-3_hu_fe87bb651bb579da.png" alt="Claude Agent SDK Part 3: The Context Control Problem" width="444" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Claude Agent SDK Part 3: The Context Control Problem</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2026/01-19-claude-agent-sdk-part-2/"></a>
	<figure class="basis-1/3 aspect-video overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2026/01-19-claude-agent-sdk-part-2_hu_31dfff7ba85c41f4.png" alt="Claude Agent SDK: Part 2" width="444" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Claude Agent SDK: Part 2</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2026/01-13-claude-cowork-first-impressions/"></a>
	<figure class="basis-1/3 aspect-video overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2026/Claude_Cowork_First_Impressions/2025-01-13_08-57-01_-_PT1_Cowork_initial_prompt_get_Lennys_transcripts_from_Dropbox_hu_a4d549a04bcbf685.png" alt="First Impressions of Claude Cowork Mode" width="444" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">First Impressions of Claude Cowork Mode</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2026/01-12-exploring-claude-agent-sdk/"></a>
	<figure class="basis-1/3 aspect-video overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2026/12-23-claude-agent-sdk_hu_38c7b10161ff92dc.png" alt="Exploring the Claude Agent SDK" width="444" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Exploring the Claude Agent SDK</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://thingsithinkithink.blog/posts/2026/01-07-christmas-break-projects/"></a>
	<figure class="basis-1/3 aspect-video overflow-hidden rounded-2xl bg-zinc-100"><img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://thingsithinkithink.blog/images/2026/01-07-christmas-game-welcome_hu_c0626d4427d544f3.png" alt="Three Things I Did Over Christmas" width="444" height="250">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Three Things I Did Over Christmas</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://thingsithinkithink.blog/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">thingsithinkithink</span>
      </a>

      <p class="font-semibold">
        
      </p>

      

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	
	
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://linkedin.com/in/davidfarrell81" target="_blank" rel="noopener noreferrer">
			<img src="/images/linkedin-color-svgrepo-com.svg" alt="LinkedIn Logo" class="w-8 h-8">
		</a>
	</li>
	
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://github.com/DavidFarrell/" target="_blank" rel="noopener noreferrer">
			<img src="/images/github-mark.svg" alt="GitHub Logo" class="w-8 h-8">
		</a>
	</li>
	<li> 
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" 
		   href="https://bsky.app/profile/dgerouvillefarrell.bsky.social" target="_blank" rel="noopener noreferrer">
			<img src="/images/Bluesky_Logo.svg" alt="Bluesky Logo" class="w-8 h-8">
		</a>
	</li>
	
	
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/about/">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/categories/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">
      Powered by 
      <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>, 
      <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> 
      and based on the 
      <a href="https://pehtheme-hugo.netlify.app/" target="_blank" rel="noopener">pehtheme</a> theme.
    </p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>