<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Infrastructure on thingsithinkithink</title>
    <link>https://thingsithinkithink.blog/tags/infrastructure/</link>
    <description>Recent content in Infrastructure on thingsithinkithink</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 08:00:00 +0000</lastBuildDate>
    <atom:link href="https://thingsithinkithink.blog/tags/infrastructure/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Three Things I Learned About Voice Agents from Kwindla Kramer</title>
      <link>https://thingsithinkithink.blog/posts/2025/07-04-voice-agents-three-insights-from-kwindla-kramer/</link>
      <pubDate>Fri, 04 Jul 2025 08:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/07-04-voice-agents-three-insights-from-kwindla-kramer/</guid>
      <description>&lt;p&gt;I learned three things from &lt;a href=&#34;https://www.youtube.com/watch?v=I86dFivLzXY&amp;amp;t=196s&#34;&gt;this interview&lt;/a&gt; with Hamel Husain and Kwindla Kramer, founder of PipeCat, an open-source framework for voice and multimodal conversation. As someone who hasn&amp;rsquo;t worked much with voice agents, I found three things particularly interesting.&lt;/p&gt;&#xA;&lt;h2 id=&#34;voice-agents-use-traditional-pipelines-not-fancy-models&#34;&gt;Voice Agents Use Traditional Pipelines, Not Fancy Models&lt;/h2&gt;&#xA;&lt;p&gt;The first thing was learning that most production voice agents don&amp;rsquo;t use the latest speech-to-speech models from OpenAI or Google (etc). Instead, they rely on a modular pipeline approach that breaks the process into discrete steps.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
