<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Interface-Design on thingsithinkithink</title>
    <link>https://thingsithinkithink.blog/tags/interface-design/</link>
    <description>Recent content in Interface-Design on thingsithinkithink</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Nov 2025 12:00:00 +0000</lastBuildDate>
    <atom:link href="https://thingsithinkithink.blog/tags/interface-design/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Evals Course Lesson 7: Interfaces for Human Review</title>
      <link>https://thingsithinkithink.blog/posts/2025/01-23-llm-evals-lesson-7-interfaces-for-human-review/</link>
      <pubDate>Sun, 23 Nov 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/01-23-llm-evals-lesson-7-interfaces-for-human-review/</guid>
      <description>&lt;p&gt;The seventh lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evaluation course&lt;/a&gt; covered interfaces for reviewing LLM outputs. This builds on &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/08-16-isaac-flath-fasthtml-annotation-tools/&#34;&gt;Isaac Flath&amp;rsquo;s vibe coding sessions&lt;/a&gt;, but focuses on design principles rather than implementation.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-review-bottleneck-problem&#34;&gt;The Review Bottleneck Problem&lt;/h2&gt;&#xA;&lt;p&gt;People talk a lot about AI doing more coding, pushing humans &amp;ldquo;higher up the stack&amp;rdquo; to do review instead of implementation. But review is already a massive bottleneck. I don&amp;rsquo;t want to manually examine 10,000 agent outputs one by one.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
