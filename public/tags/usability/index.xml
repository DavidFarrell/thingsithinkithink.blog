<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Usability on thingsithinkithink</title><link>https://thingsithinkithink.blog/tags/usability/</link><description>Recent content in Usability on thingsithinkithink</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 23 Nov 2025 12:00:00 +0000</lastBuildDate><atom:link href="https://thingsithinkithink.blog/tags/usability/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM Evals Course Lesson 7: Interfaces for Human Review</title><link>https://thingsithinkithink.blog/posts/2025/01-23-llm-evals-lesson-7-interfaces-for-human-review/</link><pubDate>Sun, 23 Nov 2025 12:00:00 +0000</pubDate><guid>https://thingsithinkithink.blog/posts/2025/01-23-llm-evals-lesson-7-interfaces-for-human-review/</guid><description>&lt;p&gt;The seventh lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s &lt;a href="https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/"&gt;LLM evaluation course&lt;/a&gt; covered interfaces for reviewing LLM outputs. This builds on &lt;a href="https://thingsithinkithink.blog/posts/2025/08-16-isaac-flath-fasthtml-annotation-tools/"&gt;Isaac Flath&amp;rsquo;s vibe coding sessions&lt;/a&gt;, but focuses on design principles rather than implementation.&lt;/p&gt;
&lt;h2 id="the-review-bottleneck-problem"&gt;The Review Bottleneck Problem&lt;/h2&gt;
&lt;p&gt;People talk a lot about AI doing more coding, pushing humans &amp;ldquo;higher up the stack&amp;rdquo; to do review instead of implementation. But review is already a massive bottleneck. I don&amp;rsquo;t want to manually examine 10,000 agent outputs one by one.&lt;/p&gt;</description></item></channel></rss>