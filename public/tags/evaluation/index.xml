<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Evaluation on thingsithinkithink</title>
    <link>https://thingsithinkithink.blog/tags/evaluation/</link>
    <description>Recent content in Evaluation on thingsithinkithink</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 22 Jun 2025 09:00:00 +0000</lastBuildDate>
    <atom:link href="https://thingsithinkithink.blog/tags/evaluation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Evals Course: Lesson 2b (office hrs)</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-22-llm-evals-course-lesson-2b-office-hrs/</link>
      <pubDate>Sun, 22 Jun 2025 09:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-22-llm-evals-course-lesson-2b-office-hrs/</guid>
      <description>&lt;p&gt;A few things I wanted to note down from the first office hours session following &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/&#34;&gt;lesson 2&lt;/a&gt; of Hamel and Shreya&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evals course&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-teams-to-actually-do-error-analysis&#34;&gt;Getting Teams to Actually Do Error Analysis&lt;/h2&gt;&#xA;&lt;p&gt;Someone asked how to actually get your team to engage with error analysis? It&amp;rsquo;s one thing to say &amp;ldquo;look at your data,&amp;rdquo; but quite another to inspire people to do the work.&lt;/p&gt;&#xA;&lt;p&gt;Shreya&amp;rsquo;s answer was straightforward: run training sessions. There&amp;rsquo;s significant activation energy required to get people over the hump, but once they experience error analysis firsthand, they become self-fuelling. The process is so valuable that people understand its worth immediately after doing it properly once.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evals Lesson 2 Error Analysis</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</link>
      <pubDate>Sat, 21 Jun 2025 12:50:38 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</guid>
      <description>&lt;p&gt;The second lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s LLM evaluation course tackled the &amp;ldquo;Analyse&amp;rdquo; phase of their evaluation lifecycle. This session focused on systematic error analysis - moving beyond gut feelings and random fixes to understand precisely where and why LLM applications fail.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://thingsithinkithink.blog/images/2025/parlancecourse/05_21_analyse_measure_improve.png&#34; alt=&#34;The evaluation lifecycle showing Analyze, Measure, and Improve phases&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re going to make something better, you need to understand how it fails and error analysis focuses on that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hamel &amp; Shreya&#39;s LLM Evals Course: Lesson 1</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</link>
      <pubDate>Sun, 08 Jun 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve started taking Hamel Husain and Shreya Shankar&amp;rsquo;s course on evaluating LLM applications. The course attracted over 700 students from more than 300 companies, which gives you a sense of how much demand there is for systematic approaches to improving AI-driven products. As someone who has taught classes with a maximum of 120 students, I&amp;rsquo;m glad it&amp;rsquo;s not me having to monitor the lesson chat.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m writing these notes here for myself as a way to come back and check what I learned from the course.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Error Analysis for Improving LLM Applications</title>
      <link>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</guid>
      <description>&lt;p&gt;I recently &lt;a href=&#34;https://www.youtube.com/watch?v=qH1dZ8JLLdU&#34;&gt;watched&lt;/a&gt; a talk by &lt;a href=&#34;https://www.linkedin.com/in/hamelhusain/&#34;&gt;Hamel Husain&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/shrshnk/&#34;&gt;Shreya Shankar&lt;/a&gt; on error analysis for LLM applications. The approach they presented offers a systematic way to improve AI systems that rely on large language models.&lt;/p&gt;&#xA;&lt;p&gt;Building LLM applications presents unique challenges since outputs are typically text-based and difficult to evaluate with traditional metrics. While many developers focus on frameworks and tools (which RAG database to use, which agentic framework to implement), Hamel and Shreya emphasise the value of looking at your data closely.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why we need Experiment-based Roadmaps in the AI Product Era</title>
      <link>https://thingsithinkithink.blog/posts/2025/04-13-why-we-need-experiment-based-roadmaps-in-the-ai-product-era/</link>
      <pubDate>Sat, 12 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/04-13-why-we-need-experiment-based-roadmaps-in-the-ai-product-era/</guid>
      <description>&lt;p&gt;I recently &lt;a href=&#34;https://www.youtube.com/watch?v=R_HnI9oTv3c&#34;&gt;watched&lt;/a&gt; a good talk by &lt;a href=&#34;https://www.linkedin.com/in/bryan-bischof/&#34;&gt;Bryan Bischoff&lt;/a&gt;, Head of AI at Theory Ventures, on why traditional product roadmaps fail for AI development and how teams should approach building AI capabilities differently. The presentation provided a good mental model for shifting from rigid planning to experimental discovery.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-problem-with-traditional-roadmaps-in-ai&#34;&gt;The Problem with Traditional Roadmaps in AI&lt;/h2&gt;&#xA;&lt;p&gt;Traditional software roadmapping focuses on time estimates for when specific features will be ready for users. Product managers meticulously plan sprints, assign engineers to swim lanes, and establish checkpoints to track progress. When teams fall behind, they reassess, potentially cutting scope or adjusting timelines.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
