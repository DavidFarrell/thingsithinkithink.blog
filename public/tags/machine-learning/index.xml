<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine-Learning on thingsithinkithink</title>
    <link>https://thingsithinkithink.blog/tags/machine-learning/</link>
    <description>Recent content in Machine-Learning on thingsithinkithink</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 21 Jun 2025 12:50:38 +0000</lastBuildDate>
    <atom:link href="https://thingsithinkithink.blog/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Evals Lesson 2 Error Analysis</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</link>
      <pubDate>Sat, 21 Jun 2025 12:50:38 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</guid>
      <description>&lt;p&gt;The second lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s LLM evaluation course tackled the &amp;ldquo;Analyse&amp;rdquo; phase of their evaluation lifecycle. This session focused on systematic error analysis - moving beyond gut feelings and random fixes to understand precisely where and why LLM applications fail.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://thingsithinkithink.blog/images/2025/parlancecourse/05_21_analyse_measure_improve.png&#34; alt=&#34;The evaluation lifecycle showing Analyze, Measure, and Improve phases&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re going to make something better, you need to understand how it fails and error analysis focuses on that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hamel &amp; Shreya&#39;s LLM Evals Course: Lesson 1</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</link>
      <pubDate>Sun, 08 Jun 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve started taking Hamel Husain and Shreya Shankar&amp;rsquo;s course on evaluating LLM applications. The course attracted over 700 students from more than 300 companies, which gives you a sense of how much demand there is for systematic approaches to improving AI-driven products. As someone who has taught classes with a maximum of 120 students, I&amp;rsquo;m glad it&amp;rsquo;s not me having to monitor the lesson chat.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m writing these notes here for myself as a way to come back and check what I learned from the course.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Error Analysis for Improving LLM Applications</title>
      <link>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</guid>
      <description>&lt;p&gt;I recently &lt;a href=&#34;https://www.youtube.com/watch?v=qH1dZ8JLLdU&#34;&gt;watched&lt;/a&gt; a talk by &lt;a href=&#34;https://www.linkedin.com/in/hamelhusain/&#34;&gt;Hamel Husain&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/shrshnk/&#34;&gt;Shreya Shankar&lt;/a&gt; on error analysis for LLM applications. The approach they presented offers a systematic way to improve AI systems that rely on large language models.&lt;/p&gt;&#xA;&lt;p&gt;Building LLM applications presents unique challenges since outputs are typically text-based and difficult to evaluate with traditional metrics. While many developers focus on frameworks and tools (which RAG database to use, which agentic framework to implement), Hamel and Shreya emphasise the value of looking at your data closely.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
