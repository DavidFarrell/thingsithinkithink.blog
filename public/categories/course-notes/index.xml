<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course-Notes on thingsithinkithink</title>
    <link>https://thingsithinkithink.blog/categories/course-notes/</link>
    <description>Recent content in Course-Notes on thingsithinkithink</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 Oct 2025 12:00:00 +0000</lastBuildDate>
    <atom:link href="https://thingsithinkithink.blog/categories/course-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Evals Course Lesson 5: How to Evaluate Complex Architectures</title>
      <link>https://thingsithinkithink.blog/posts/2025/10-11-llm-evals-course-lesson-5-how-to-evaluate-complex-architectures/</link>
      <pubDate>Sat, 11 Oct 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/10-11-llm-evals-course-lesson-5-how-to-evaluate-complex-architectures/</guid>
      <description>&lt;p&gt;The fifth lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evaluation course&lt;/a&gt; moved into evaluating more complex systems. Previous lessons focused on single-step evaluation, but this session addressed RAG systems, tool calling, and other architectures that introduce additional components to evaluate.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;re still in the analyse-measure phase of the evaluation lifecycle. The focus remains on understanding issues and identifying failure modes rather than implementing improvements.&lt;/p&gt;&#xA;&lt;h2 id=&#34;rag-isnt-dead&#34;&gt;RAG Isn&amp;rsquo;t Dead&lt;/h2&gt;&#xA;&lt;p&gt;The early post-ChatGPT period saw considerable attention on RAG implementation details - chunking strategies, vector databases, embedding models. Whilst these details matter, they became the single greatest focus when they&amp;rsquo;re just one part of a larger system.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evals Course Lesson 4: Multi-turn and Collaborative Evaluation</title>
      <link>https://thingsithinkithink.blog/posts/2025/08-21-llm-evals-course-lesson-4-multiturn-collaborative-evaluation/</link>
      <pubDate>Thu, 21 Aug 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/08-21-llm-evals-course-lesson-4-multiturn-collaborative-evaluation/</guid>
      <description>&lt;p&gt;The fourth lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evaluation course&lt;/a&gt; covered two distinct challenges: evaluating multi-turn conversations and building evaluation criteria through collaboration.&lt;/p&gt;&#xA;&lt;h2 id=&#34;part-one-multi-turn-evaluation-beyond-single-exchanges&#34;&gt;Part One: Multi-turn Evaluation Beyond Single Exchanges&lt;/h2&gt;&#xA;&lt;p&gt;Multi-turn evaluation presents unique challenges compared to single-turn interactions. The same analyse-measure-improve lifecycle applies, and binary criteria remain a good starting point. But conversations introduce new dimensions to consider.&lt;/p&gt;&#xA;&lt;h3 id=&#34;what-changes-with-multi-turn&#34;&gt;What Changes with Multi-turn&lt;/h3&gt;&#xA;&lt;p&gt;When evaluating multi-turn conversations, three aspects come into play that don&amp;rsquo;t matter as much with individual turns:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evals Course Lesson 3: Building Automated Evaluators</title>
      <link>https://thingsithinkithink.blog/posts/2025/07-06-llm-evals-course-lesson-3-automated-evaluators/</link>
      <pubDate>Sun, 06 Jul 2025 08:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/07-06-llm-evals-course-lesson-3-automated-evaluators/</guid>
      <description>&lt;p&gt;The third lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evaluation course&lt;/a&gt; moved from manual error analysis into automated evaluation systems. This session focused on the &amp;ldquo;Measure&amp;rdquo; phase of their evaluation lifecycle - how to build evaluators that can automatically detect the failure modes we identified through error analysis.&lt;/p&gt;&#xA;&lt;p&gt;In terms of the Three Gulfs Model from lesson one, this lesson first helps us distinguish between specification failures (where we need to improve our prompts) and generalisation failures (where the LLM struggles despite clear instructions). The automated evaluators we build specifically target the Gulf of Generalisation, measuring how well our LLM applies instructions across diverse inputs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evals Course: Lesson 2b (office hrs)</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-22-llm-evals-course-lesson-2b-office-hrs/</link>
      <pubDate>Sun, 22 Jun 2025 09:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-22-llm-evals-course-lesson-2b-office-hrs/</guid>
      <description>&lt;p&gt;A few things I wanted to note down from the first office hours session following &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/&#34;&gt;lesson 2&lt;/a&gt; of Hamel and Shreya&amp;rsquo;s &lt;a href=&#34;https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/&#34;&gt;LLM evals course&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;getting-teams-to-actually-do-error-analysis&#34;&gt;Getting Teams to Actually Do Error Analysis&lt;/h2&gt;&#xA;&lt;p&gt;Someone asked how to actually get your team to engage with error analysis? It&amp;rsquo;s one thing to say &amp;ldquo;look at your data,&amp;rdquo; but quite another to inspire people to do the work.&lt;/p&gt;&#xA;&lt;p&gt;Shreya&amp;rsquo;s answer was straightforward: run training sessions. There&amp;rsquo;s significant activation energy required to get people over the hump, but once they experience error analysis firsthand, they become self-fuelling. The process is so valuable that people understand its worth immediately after doing it properly once.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Evals Lesson 2 Error Analysis</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</link>
      <pubDate>Sat, 21 Jun 2025 12:50:38 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-21-llm-evals-lesson-2-error-analysis/</guid>
      <description>&lt;p&gt;The second lesson of Hamel Husain and Shreya Shankar&amp;rsquo;s LLM evaluation course tackled the &amp;ldquo;Analyse&amp;rdquo; phase of their evaluation lifecycle. This session focused on systematic error analysis - moving beyond gut feelings and random fixes to understand precisely where and why LLM applications fail.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://thingsithinkithink.blog/images/2025/parlancecourse/05_21_analyse_measure_improve.png&#34; alt=&#34;The evaluation lifecycle showing Analyze, Measure, and Improve phases&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re going to make something better, you need to understand how it fails and error analysis focuses on that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hamel &amp; Shreya&#39;s LLM Evals Course: Lesson 1</title>
      <link>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</link>
      <pubDate>Sun, 08 Jun 2025 12:00:00 +0000</pubDate>
      <guid>https://thingsithinkithink.blog/posts/2025/06-08-llm-evals-lesson-1/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve started taking Hamel Husain and Shreya Shankar&amp;rsquo;s course on evaluating LLM applications. The course attracted over 700 students from more than 300 companies, which gives you a sense of how much demand there is for systematic approaches to improving AI-driven products. As someone who has taught classes with a maximum of 120 students, I&amp;rsquo;m glad it&amp;rsquo;s not me having to monitor the lesson chat.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m writing these notes here for myself as a way to come back and check what I learned from the course.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
