<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Development on thingsithinkithink</title><link>https://thingsithinkithink.blog/categories/development/</link><description>Recent content in Development on thingsithinkithink</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 13 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://thingsithinkithink.blog/categories/development/index.xml" rel="self" type="application/rss+xml"/><item><title>Error Analysis for Improving LLM Applications</title><link>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</link><pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate><guid>https://thingsithinkithink.blog/posts/2025/04-13-error-analysis-for-improving-llm-applications/</guid><description>&lt;p&gt;I recently &lt;a href="https://www.youtube.com/watch?v=qH1dZ8JLLdU"&gt;watched&lt;/a&gt; a talk by &lt;a href="https://www.linkedin.com/in/hamelhusain/"&gt;Hamel Husain&lt;/a&gt; and &lt;a href="https://www.linkedin.com/in/shrshnk/"&gt;Shreya Shankar&lt;/a&gt; on error analysis for LLM applications. The approach they presented offers a systematic way to improve AI systems that rely on large language models.&lt;/p&gt;
&lt;p&gt;Building LLM applications presents unique challenges since outputs are typically text-based and difficult to evaluate with traditional metrics. While many developers focus on frameworks and tools (which RAG database to use, which agentic framework to implement), Hamel and Shreya emphasise the value of looking at your data closely.&lt;/p&gt;</description></item></channel></rss>